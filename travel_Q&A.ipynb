{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSWkikKptiUw"
      },
      "source": [
        "**1.Data** **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fsvtLW4tIas",
        "outputId": "504740ff-be1f-460e-932f-8670229e5188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded files: ['customer_feedbacks.txt', 'flight_cancellations.txt', 'airline_policies.txt', 'travel_trends_2024.txt']\n",
            "Total chunks created: 13\n",
            "Saved: processed/travel_chunks.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load raw text files\n",
        "# -------------------------------\n",
        "DATA_DIR = \".\"\n",
        "\n",
        "def load_documents(folder):\n",
        "    docs = {}\n",
        "    for file in os.listdir(folder):\n",
        "        if file.endswith(\".txt\"):\n",
        "            path = os.path.join(folder, file)\n",
        "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "                docs[file] = f.read()\n",
        "    return docs\n",
        "\n",
        "documents = load_documents(DATA_DIR)\n",
        "\n",
        "print(\"Loaded files:\", list(documents.keys()))\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Basic cleaning\n",
        "# -------------------------------\n",
        "def clean_text(text):\n",
        "    text = text.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
        "    text = re.sub(r\" +\", \" \", text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "documents = {name: clean_text(text) for name, text in documents.items()}\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Semantic Chunking\n",
        "# Chunk size: 300\u2013500 tokens (ideal for LLM retrieval)\n",
        "# -------------------------------\n",
        "\n",
        "def smart_chunk(text, max_length=500):\n",
        "    # split on sentence boundaries\n",
        "    sentences = re.split(r\"(?<=[.!?]) +\", text)\n",
        "\n",
        "    chunks = []\n",
        "    current = \"\"\n",
        "\n",
        "    for s in sentences:\n",
        "        if len(current.split()) + len(s.split()) <= max_length:\n",
        "            current += \" \" + s\n",
        "        else:\n",
        "            chunks.append(current.strip())\n",
        "            current = s\n",
        "\n",
        "    if current:\n",
        "        chunks.append(current)\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# Create structured chunk objects\n",
        "all_chunks = []\n",
        "chunk_id = 0\n",
        "\n",
        "for filename, text in documents.items():\n",
        "    chunks = smart_chunk(text)\n",
        "\n",
        "    for ch in chunks:\n",
        "        all_chunks.append({\n",
        "            \"chunk_id\": f\"chunk_{chunk_id}\",\n",
        "            \"source\": filename,\n",
        "            \"text\": ch\n",
        "        })\n",
        "        chunk_id += 1\n",
        "\n",
        "print(\"Total chunks created:\", len(all_chunks))\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Save chunks to JSON\n",
        "# -------------------------------\n",
        "os.makedirs(\"processed\", exist_ok=True)\n",
        "\n",
        "with open(\"processed/travel_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(all_chunks, f, indent=2)\n",
        "\n",
        "print(\"Saved: processed/travel_chunks.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiL6Y7OnziIW"
      },
      "source": [
        "**2. Embeddings + FAISS Index Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542,
          "referenced_widgets": [
            "8d8939ad46fb45118b6748ebe9536577",
            "3a24492889014c5fa844f2fd32727218",
            "a4a0c95925f64bb98dca78fe13e088da",
            "9b2459c0548f4a3b92f7cdc057e8e91b",
            "32035b7fc861437f855faa34f9e03509",
            "5dc41e339f1a4d2c8a3093b85c507966",
            "0dafc61d863e41d2ac69586827ab45c2",
            "fe9dfa9ffc8f405e83db482ae886f895",
            "0678c17505654babbcfc92cee79291df",
            "cfbb292be1674b6a86c687a2b178074b",
            "038f05541c1c4d2395cd75800b9d1821",
            "c9b61001d1024f85905c07eedb47adc3",
            "7ba759f595fb4984b4d62cbac0d2f4f9",
            "e4dbcdbbc8304499988f313edcc0652e",
            "9a2e2a231ce347729a3e380d50ca79dd",
            "68b121a68e6a425e8d60cabd22432e20",
            "1d683fd6be4a4510ae77acf870a6d4d0",
            "1190036a74c34936ae311a7eb47504d1",
            "ffb3bb06880f4b00890192cdddcf6fa2",
            "98be4d2bdd3f4a44a55a5d924e3058c3",
            "d9572964bce940caacb0445987b3b53c",
            "187ab8153b9c4b8db19888d733ff1aa0",
            "269108e315d441fe855885ef924a5514",
            "677a5cf71d624063b8a80d9658686400",
            "89b6fb732eff4e699ecb934f5842ff39",
            "86a1b36b59b8415aa6fcb5962d2f5f71",
            "346ecaadeaa646b59632a3882c71fba8",
            "f565649e87504a14a6d3159757dd23e9",
            "c18455ddf85b461d8be7c493354b1973",
            "1e993d0da7ee4569877d392760366f91",
            "f5faf8df17224320ae171e6ae772faf5",
            "97c3f6d822d04771a02ce8596b30bfcf",
            "a9ba8d629216466c85ded3d2cd88e166",
            "37ea9963dc454e35a9e5c2e6ac6ff885",
            "e8d16f5b4c34458985b34576b53757d8",
            "663ff36a5c2349c99b8d2b3609b36148",
            "c0224fde2f974b71a962d94de64a92cd",
            "748b5124906f471a94f208c8c6409b9f",
            "3a9d78cdb6af4fcab277ecad7d0c240c",
            "a9ceea8b68a64d2b8512a5476c91d465",
            "2b7e36d5f8ec4819bbc2eac7ad35ac88",
            "181d1f6ab40f4d32bd12aed4923a971f",
            "596fcd34fe4e451c927c06ca315d60b9",
            "c10fcd29951240649859b824b2949d48",
            "cc849ac2298d439494eb9a420671bc0f",
            "de64e14235874857a7cd3f35cf11a7bf",
            "3047fffbbcb94ef18e461a2f712dd904",
            "164e1ac12b054ce9b3cd4d21d474598f",
            "ac5b78ee587f459d91bdb382ea5dae3b",
            "bb04864e60374c5a884302ed3aea6ccf",
            "2eb67d844872468faca1efb0c3f18127",
            "23d0652a506546588a2d4308ccdecc76",
            "1f68c00181a742d88b505c9d574af8c2",
            "a2db3c6c55f747788b8809da7f139f86",
            "33c1addc982f4c8c8d212d607e30b5f3",
            "b557d49f380a48d4b4689ef76c37d36f",
            "857f3887a1c1465d83ab2099045e2816",
            "1c53263e0b264c5cab87f8ecc60f1971",
            "417a8575dd814e49a3845391ed7226ae",
            "39f1c9d8cd214ab096d1e562aa58172c",
            "092c16a0103046fc8e62be3009055b5f",
            "160bcdc7413943dc901adde419218f7e",
            "f5dd1b0e975949bba1c96808dd9d838b",
            "f240cd7f45934cb3afc5ab3c5b98454c",
            "be12252cda9c45c0822d5c6c8ceaf0b6",
            "cc12687ece83477386954bd321025cee",
            "e7308eeb3fb946f4a621951a0c693703",
            "2d5e042468014e7297fe5ad82879ed07",
            "3a24cecb589c4a2da623abe646872bc2",
            "ce908a32846e40f398439445dfde7b1d",
            "ee71f08db4134eca9784c96df261d361",
            "df5129350dac494b8a866fc06482f95b",
            "d331926f5173433db4e5597a80b95b98",
            "33823d97b5d444208819bad3d3f4eeec",
            "abc791c57dde4dfd93fb50fafce84e6b",
            "4c386e342e954d54bbee9404c4c5b40d",
            "5a4f81331b474517b745ddf0e7ceaf47",
            "6b172884ab5840eb9fb30091e4017100",
            "a4a878e1fa1d4944b42103abfbfe0595",
            "14fd0689ada0482bad0902039421caf5",
            "354e908a8af543289ad096ee24397f43",
            "ec9463918da24c7eb3429ebc554239f0",
            "d400cd31187a4b2c90b0b06a4d469c86",
            "838a35dccc744d91aaeee7940adf970a",
            "40dfbe5a1ee04d159049d28d959d04e0",
            "b3ca429c74fe479f9090be05c9ba63ac",
            "59c318e3edf54b90a85d64c89b43e9d2",
            "3092e3aecb3845f8adeca049422e74ac",
            "cf4b80f7dabd49ecaa076b22a28fdaa8",
            "6c29e57eba494ecb915e45ca2ec13c73",
            "6ca7fb56412240a9bf02c02f80dfee89",
            "2958272ff0a5498ea7ad23d75fcc0f15",
            "718ba8d848db46988bdcda4a3cc550e7",
            "5b1e9495518b42538ce6fc075f8102de",
            "a9ccfb560fb940b48a14906ea577d7cc",
            "53ede276eb134435b9baf2ecf6a589c6",
            "38f7f490b3e342f7800ba77a1ac6b436",
            "9e140c5b63224d7fa70124c1d56c7d77",
            "ef1e60a488ef47ecb842d8893ce60e00",
            "4334190efa3f48fb95d2d9dd30f20690",
            "8cef1c86088d47949275c0e1e9580840",
            "9720432faa184c2fa17a4f74b9f59710",
            "7d94bc8d06984521993df0d58d02bc9f",
            "5eb59012d9734f118ee15f21d8b152a1",
            "b4c6553feb7f442488d219919085b74d",
            "b13401787a3249a5af71ea9a1f8b82bb",
            "76335d26e77f4080ad0d099c8fe8d17e",
            "5173e7d27126409686a2580f42416dca",
            "d829e523c79a45fb87f7cd8e207bb1fc",
            "062f9b583d724381b5f4f2512edf92e9",
            "05a7df3dffc9469d95f6cc510b37d125",
            "1b82809f8f1c4c71b498b66c7adbaa3d",
            "3760dd2b0e2b4c35a690a793302e7f90",
            "f10c4f145f6045c0809763b567366d23",
            "b11b2c60c6d54ba487d3ce3e3ec3f117",
            "561bcd1bda844fb7874036ea71ee1a50",
            "cc4e199062b34d88a13980f567758cf1",
            "b8f664942d5140a9a39c7af3753f72d9",
            "6689456b33444848af4d6125920fabcd",
            "635deb90237d48e3ac524d86fe1178b9",
            "515582289c3c4df6a207f53201d985a8",
            "de527123228543249f6cc126cccfe023",
            "f0587524c76c4e99a2e75a303516ffc9",
            "85566b79c2d74c2e9de133617342b568",
            "f92835f18ed543669e137b1325decb66",
            "c012ba82bd3941d7bf580654a5b54cd5",
            "4c6605c87d504a85bd38adb1f0b8a0d4",
            "64d41c2e11a942598ee4bbef9ce2deb7",
            "e8cd539357ba414b8a925b8d24d9e372",
            "e8e71e87064b47aea40c6e131a2a1f53",
            "8d2c73b692204f9db952d07896d9372e",
            "e13c76ffe4a949dfadbe2da63f85215c"
          ]
        },
        "id": "-CSWvqIWzjJW",
        "outputId": "707d3485-75d5-433a-d3d2-18074d556d5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d8939ad46fb45118b6748ebe9536577",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9b61001d1024f85905c07eedb47adc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "269108e315d441fe855885ef924a5514",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37ea9963dc454e35a9e5c2e6ac6ff885",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc849ac2298d439494eb9a420671bc0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b557d49f380a48d4b4689ef76c37d36f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7308eeb3fb946f4a621951a0c693703",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b172884ab5840eb9fb30091e4017100",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf4b80f7dabd49ecaa076b22a28fdaa8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4334190efa3f48fb95d2d9dd30f20690",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05a7df3dffc9469d95f6cc510b37d125",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de527123228543249f6cc126cccfe023",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS index and metadata saved!\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "import json\n",
        "\n",
        "# Load chunks\n",
        "with open(\"processed/travel_chunks.json\", \"r\") as f:\n",
        "    chunks = json.load(f)\n",
        "\n",
        "texts = [c[\"text\"] for c in chunks]\n",
        "\n",
        "# -------------------------------\n",
        "# Create embeddings\n",
        "# -------------------------------\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = model.encode(texts, show_progress_bar=True)\n",
        "\n",
        "embeddings = np.array(embeddings).astype(\"float32\")\n",
        "\n",
        "# -------------------------------\n",
        "# Build FAISS index\n",
        "# -------------------------------\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n",
        "\n",
        "faiss.write_index(index, \"processed/travel_faiss.index\")\n",
        "\n",
        "# Save metadata (mapping)\n",
        "with open(\"processed/travel_metadata.json\", \"w\") as f:\n",
        "    json.dump(chunks, f, indent=2)\n",
        "\n",
        "print(\"FAISS index and metadata saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP9JHk-Cz9JK",
        "outputId": "48674b20-d200-4f8a-df25-c81b94321271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI4RTpwU21VU"
      },
      "source": [
        "**3. Retrieval + Multi-Hop RAG Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkJ98zZM0BW0"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "import json\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from openai import OpenAI\n",
        "\n",
        "# -------------------------------\n",
        "# Load FAISS + metadata\n",
        "# -------------------------------\n",
        "index = faiss.read_index(\"processed/travel_faiss.index\")\n",
        "\n",
        "with open(\"processed/travel_metadata.json\") as f:\n",
        "    chunks = json.load(f)\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# -------------------------------\n",
        "# Retrieval function\n",
        "# -------------------------------\n",
        "def retrieve(query, k=3):\n",
        "    q_emb = model.encode([query]).astype(\"float32\")\n",
        "    distances, idx = index.search(q_emb, k)\n",
        "\n",
        "    results = []\n",
        "    for i in idx[0]:\n",
        "        results.append(chunks[i])\n",
        "    return results\n",
        "\n",
        "# -------------------------------\n",
        "# Multi-hop RAG\n",
        "# -------------------------------\n",
        "def rag_answer(query):\n",
        "    retrieved = retrieve(query, k=5)\n",
        "\n",
        "    context = \"\\n\\n\".join(\n",
        "        [f\"[{c['source']}] {c['text']}\" for c in retrieved]\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a travel analytics assistant. Use ONLY the context below.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer clearly with combined insights across documents.\n",
        "\"\"\"\n",
        "\n",
        "    client = OpenAI(api_key=\"enter here openai api key\")\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0iJfB_Q3g1G",
        "outputId": "6243cc77-98f8-4538-a3ee-1cf0953a297e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The airline with the most cancellations in 2024 was IndiGo, with a total of 8,920 cancellations. The primary reasons for these cancellations were weather events, particularly dense fog, which accounted for a significant portion of the cancellations (48% of total cancellations in the year). Additionally, technical and maintenance issues contributed to 31% of the cancellations, while crew shortages and operational bottlenecks accounted for 15%. The worst-affected routes included Delhi\u2013Mumbai and Delhi\u2013Srinagar, with the heavy prevalence of fog significantly impacting operations during winter months. This trend continued throughout the year, leading to numerous cancellations primarily driven by adverse weather conditions.\n"
          ]
        }
      ],
      "source": [
        "print(rag_answer(\"Which airline had the most cancellations in 2024 and why?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azKH50ro3umN",
        "outputId": "ae54004c-17fb-494a-d63d-081b40cf8ee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The airline that both boasted record bookings early in the year and later reduced payload due to extreme heat is Indigo. In January, Indigo claimed \"record bookings,\" but by May, due to extreme heat conditions reaching temperatures above 45\u00b0C, the airline issued an internal memo instructing crews to reduce payload by 800 kg on high-temperature days. This meant fewer passengers, less baggage, and more cancellations.\n"
          ]
        }
      ],
      "source": [
        "print(rag_answer(\"Which airline both boasted record bookings early in the year and later reduced payload due to extreme heat?\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1w5trE66PPu",
        "outputId": "5bf268b1-d01f-4a33-cbd7-42f028aa2c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The narrative around Goa tourism highlighted a stark contrast between large resorts and small boutique hotels. \n",
            "\n",
            "Large resorts, commonly blamed for \"overtourism,\" were experiencing low occupancy rates, around 42%. They had built large establishments anticipating a return to pre-pandemic levels of tourism, which did not materialize, leading to frustrations over empty rooms. Their marketing focused on attracting traditional vacationers, families, and leisure tourists, which ultimately did not translate into expected demand.\n",
            "\n",
            "In contrast, small boutique hotels were benefiting significantly, with one owner noting a remarkable 68% increase in bookings. These establishments attracted a different demographic\u2014primarily tech professionals from Bengaluru who were traveling for workations. They were flexible, preferring to fly in on weekends to work remotely while enjoying the beach. This shift had prompted the boutique hotel to adapt by converting spaces for co-working, thus catering to the needs of this emerging trend.\n",
            "\n",
            "This divergence illustrates how smaller, adaptive businesses thrived by embracing the changing patterns of tourism, while larger resorts struggled to balance their scale with the current market dynamics.\n"
          ]
        }
      ],
      "source": [
        "print(rag_answer(\"How did the narrative around Goa tourism differ between large resorts and small boutique hotels?\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkANgoyH6daW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}